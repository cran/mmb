% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bayesNaive.R
\name{bayesProbabilityNaive}
\alias{bayesProbabilityNaive}
\title{Naive Bayesian inferencing for determining the probability or
relative likelihood of a given value.}
\usage{
bayesProbabilityNaive(
  df,
  features,
  targetCol,
  selectedFeatureNames = c(),
  shiftAmount = 0.1,
  retainMinValues = 1,
  doEcdf = FALSE,
  useParallel = NULL
)
}
\arguments{
\item{df}{data.frame that contains all the feature's data}

\item{features}{data.frame with bayes-features. One of the features needs
to be the label-column.}

\item{targetCol}{string with the name of the feature that represents the
label.}

\item{selectedFeatureNames}{vector default \code{c()}. Vector of strings
that are the names of the features the to-predict label depends on. If an
empty vector is given, then all of the features are used (except for the
label). The order then depends on the features' order.}

\item{shiftAmount}{numeric an offset value used to increase any one
probability (factor) in the full built equation. In scenarios with many
dependencies, it is more likely that a single conditional probability
becomes zero, which would result in the entire probability being zero.
Since this is often useless, the 'shiftAmount' can be added to each
factor, resulting in a non-zero probability that can at least be used
to order samples by likelihood. Note that, with a positive 'shiftAmount',
the result of this function cannot be said to be a probability any
longer, but rather results in a comparable likelihood (a 'probability
score').}

\item{retainMinValues}{integer to require a minimum amount of data points
when segmenting the data feature by feature.}

\item{doEcdf}{default FALSE a boolean to indicate whether to use the
empirical CDF to return a probability when inferencing a continuous
feature. If false, uses the empirical PDF to return the rel. likelihood.
This parameter does not have any effect if all of the variables are
discrete or when doing a regression. Otherwise, for each continuous
variable, the probability to find a value less then or equal - given
the conditions - is returned. Note that the interpretation of probability
using the ECDF much deviates and must be used with care, especially
since it affects each factor in Bayes equation that is continuous. This
is especially true for the case where \code{shiftAmount > 0}.}

\item{useParallel}{default NULL a boolean to indicate whether to use a
previously registered parallel backend. If no explicit value was given,
calls \code{foreach::getDoParRegistered()} to check for a parallel
backend. When using parallelism, this function calculates each factor
in the numerator and denominator of the final equation in parallel.}
}
\value{
numeric probability (inferring discrete labels) or relative
likelihood (regression, inferring likelihood of continuous value) or most
likely value given the conditional features. If using a positive
\code{shiftAmount}, the result is a 'probability score'.
}
\description{
A complementary implementation using methods common in mmb,
such as computing factors or segmenting data. Supports Laplacian smoothing
and early-stopping segmenting, as well as PDF and CDF and selecting any
subset of features for dependency.
}
\examples{
feat1 <- mmb::createFeatureForBayes(
  name = "Petal.Length", value = mean(iris$Petal.Length))
feat2 <- mmb::createFeatureForBayes(
  name = "Petal.Width", value = mean(iris$Petal.Width))
featT <- mmb::createFeatureForBayes(
  name = "Species", iris[1,]$Species, isLabel = TRUE)

# Check the probability of Species=setosa, given the other 2 features:
mmb::bayesProbabilityNaive(
  df = iris, features = rbind(feat1, feat2, featT), targetCol = "Species")

# Now check the probability of Species=versicolor:
featT$valueChar <- "versicolor"
mmb::bayesProbabilityNaive(
  df = iris, features = rbind(feat1, feat2, featT), targetCol = "Species")
}
\author{
Sebastian HÃ¶nel \href{mailto:sebastian.honel@lnu.se}{sebastian.honel@lnu.se}
}
\keyword{classification}
\keyword{inferencing}
\keyword{naive}
